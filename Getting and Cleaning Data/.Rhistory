swirl()
read.csv(path2csv, stringsAsFactors = FALSE)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageversion("dplyr")
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?manip
select(cran, ip_id, package, country)
5:20
select(cran, r_arch_country)
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
select(cran, !(X:size))
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_is == "linux_gnu")
filter(cran, size > 100500, r_os == "linux_gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
head(top_counts, 20)
arrange(top_counts, desc(count))
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
top_unique
arrange(top_unique, desc(unique))
submit()
submit()
submit()
submit()
submit()
submit()
submit()
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res, sex_class, c("sex", "class"))
submit()
students3
submit()
?spread()
?spread
gather(students3, class, grade, class1:class5, na.rm = TRUE)
spread(gather(students3, class, grade, class1:class5, na.rm = TRUE), test, value)
submit()
submit()
extract_numeric("class5")
submit()
?mutate
submit()
spread(gather(students3, class, grade, class1:class5, na.rm = TRUE), test, grade)
mutate(spread(gather(students3, class, grade, class1:class5, na.rm = TRUE), test, grade), class = extract_numeric(class))
submit()
submit()
skip()
students4
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
passed
failed
mutate(passed, status = "passed")
passed < passed %>% mutate(status = "passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
rbind_list(passed, failed)
sat
?separate
submit()
?group_by
submit()
submit()
rm(list = ls())
setwd('C://Users//ABaker//Documents//GitHub//Coursera//Getting and Cleaning Data')
acs <- read.csv("./data/acs_wk3.csv")
str(acs)
head(acs)
table(acs$ACR)
table(acs$AGS)
acs[acs$ACR == 3 && acs$AGS == 6,]
table(acs$AGS)
acs$ACR == 3
acs$AGS == 6
acs[acs$ACR == 3 && acs$AGS == 6,]
which(acs[acs$ACR == 3 && acs$AGS == 6,])
acs[acs$ACR == 3,]
head(acs[acs$ACR == 3,])
Url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
if(!file.exists("./data/acs_wk3.csv")) {download.file(Url, destfile = "./data/acs_wk3.csv")}
acs <- read.csv("./data/acs_wk3.csv")
str(acs)
head(acs)
head(acs[acs$ACR == 3,])
head(acs)
head(acs[acs$ACR == 3 & acs$AGS == 6,])
nrow(acs[acs$ACR == 3 & acs$AGS == 6,])
acs$ACR == 3 & acs$AGS == 6
agricultureLogical <- acs$ACR == 3 & acs$AGS == 6
which(agricultureLogical)
?which
acs[125,]
if(!file.exists("./data/q2_wk3.jpg")) {download.file(Url, destfile = "./data/q2_wk3.jpg", mode="wb")}
list.files(".data")
list.files("./data")
?read.jpeg
?read.jpg
?jpeg
if(!file.exists("./data/q2_wk3.jpg")) {download.file(url2, destfile = "./data/q2_wk3.jpg", mode="wb")}
?download.file()
?jpeg
if(!file.exists("./data/q2_wk3.jpg")) {download.file(url2, destfile = "./data/q2_wk3.jpg", mode="wb")}
url2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
if(!file.exists("./data/q2_wk3.jpg")) {download.file(url2, destfile = "./data/q2_wk3.jpg", mode="wb")}
jpeg(filename = "./data/q2_wk3.jpg", native=TRUE)
jpg <- jpeg(filename = "./data/q2_wk3.jpg")
head(jpg)
library(jpeg)
library(readJPEG)
install.packages("jpeg")
library(jpeg)
?jpeg
?readJPEG
img <- readJPEG("./data/q2_wk3.jpg", native = TRUE)
if(!file.exists("./data/q2_wk3.jpg")) {download.file(url2, destfile = "./data/q2_wk3.jpg", mode="wb")}
img <- readJPEG("./data/q2_wk3.jpg", native = TRUE)
url2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
if(!file.exists("./data/q2_wk3.jpg")) {download.file(url2, destfile = "./data/q2_wk3.jpg", mode="wb")}
setwd('C://Users//ABaker//Documents//GitHub//Coursera//Getting and Cleaning Data')
library(jpeg)
rm(list = ls())
library(jpeg)
url2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
if(!file.exists("./data/q2_wk3.jpg")) {download.file(url2, destfile = "./data/q2_wk3.jpg", mode="wb")}
img <- readJPEG("./data/q2_wk3.jpg", native = TRUE)
head(jpg)
head(img)
?quantile
str(img)
quantile(img, c(0.3, 0.8))
url3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
if(!file.exists("./data/wk3_GDP.csv")) {download.file(url3, destfile = "./data/wk3_GDP.csv")}
if(!file.exists("./data/wk3_Country.csv")) {download.file(url4, destfile = "./data/wk3_Country")}
gdp <- read.csv("./data/wk3_GDP.csv")
country <- read.csv("./data/wk3_Country.csv")
if(!file.exists("./data/wk3_GDP.csv")) {download.file(url3, destfile = "./data/wk3_GDP.csv")}
if(!file.exists("./data/wk3_Country.csv")) {download.file(url4, destfile = "./data/wk3_Country.csv")}
gdp <- read.csv("./data/wk3_GDP.csv")
country <- read.csv("./data/wk3_Country.csv")
head(gdp)
head(country)
head(gdp,2)
head(country,2)
?read.csv
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5, col.names = c("Country.Code", "Ranking", "Economy", "USD"))
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5, col.names = c("Country.Code", "Ranking", "Economy", "USD", "x"))
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5, col.names = c("Country.Code", "Ranking", "Economy", "USD", "x", "y"))
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5, col.names = c("Country.Code", "Ranking", "Economy", "USD", "x", "y", "z"))
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5, col.names = c("Country.Code", "Ranking", "Economy", "USD", "x", "y", "z", "1"))
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5, col.names = c("Country.Code", "Ranking", "Economy", "USD", "x", "y", "z", "1", "2"))
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5)
head(gdp,2)
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5, col.names = c("Country.Code", "Rank", "V1", "Country.Name", "GDP", "V2", "V3", "V4", "V5", "V6"))
head(gdp,2)
head(gdp,2)
head(gdp)
gdp <- gdp[c(1,2,4,5),]
head(gdp)
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5, col.names = c("Country.Code", "Rank", "V1", "Country.Name", "GDP", "V2", "V3", "V4", "V5", "V6"))
head(gdp)
gdp[,c(1,2,4,5)]
head(gdp[,c(1,2,4,5)])
gdp <- gdp[,c(1,2,4,5)]
table(gdp)
gdp
str(gdp)
str(gdp)
gdp$Rank
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5, col.names = c("Country.Code", "Rank", "V1", "Country.Name", "GDP", "V2", "V3", "V4", "V5", "V6"))
gdp <- gdp[gdp$Rank <= 190, c(1,2,4,5)]
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5,
col.names = c("Country.Code", "Rank", "V1", "Country.Name",
"GDP", "V2", "V3", "V4", "V5", "V6"),
stringsAsFactors = FALSE)
gdp <- gdp[gdp$Rank <= 190, c(1,2,4,5)]
gdp
gdp[gdp$Rank == 4,]
gdp$Rank
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5,
col.names = c("Country.Code", "Rank", "V1", "Country.Name",
"GDP", "V2", "V3", "V4", "V5", "V6"))
head(gdp)
summary(gdp)
str(gdp)
gdp <- gdp[,c(1,2,4,5)]
summary(gdp)
str(gdp)
gdp
gdp[1:190,]
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5,
col.names = c("Country.Code", "Rank", "V1", "Country.Name",
"GDP", "V2", "V3", "V4", "V5", "V6"))
gdp <- gdp[1:190,c(1,2,4,5)]
head(gdp)
gdp[gdp$Rank < 10,]
gdp[gdp$Country.Name == 'France', ]
as.numeric(gdp$Rank)
country <- read.csv("./data/wk3_Country.csv")
head(country)
head(country)
gdp[Rank == 1,]
gdp[gdp$Rank == 1,]
head(country)
mergedData = merge(gdp, country, by.x="Country.Code", by.y="CountryCode", all=TRUE)
head(mergedData)
gdp[gdp$Country.Code == "ADO",]
gdp[gdp$Country.Code == "USA",]
head(mergedData)
nrow(mergedData)
mergedData = merge(gdp, country, by.x="Country.Code", by.y="CountryCode")
nrow(mergedData)
mergedData[with(mergedData, order(Rank)),]
mergedData[with(mergedData, order(Rank)), c(mergedData$Rank, mergedData$Country.Code)]
mergedData$Rank
mergedData$Country.Code
mergedData[with(mergedData, order(Rank)), c(mergedData$Rank, mergedData$Country.Code)]
mergedData[with(mergedData, order(Rank)), ]
head(mergedData[with(mergedData, order(Rank)), ])
setwd('C:/Users/ABaker/Documents/GitHub/Coursera/Getting and Cleaning Data')
getwd()
ls()
list.files()
rm(list=ls())
ls()
list.files()
list.files("./data")
acSurveyData <- read.csv("./data/ac_survey.csv")
head(acSurveyData)
DT = data.table(acSurveyData)
nrow(DT) # 6496
library(data.table)
DT = data.table(acSurveyData)
nrow(DT) # 6496
nrow(DT[DT$VAL==24]) # Answer = 53
library(xlsx)
colIndex <- 7:15
rowIndex <- 18:23
dat <- read.xlsx("./data/gas_program.xlsx",sheetIndex=1,
colIndex=colIndex,rowIndex=rowIndex)
dat
sum(dat$Zip*dat$Ext,na.rm=T) # 36534720
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
library(XML)
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
DTzips = data.table(xpathSApply(rootNode,"//zipcode",xmlValue))
nrow(DTzips[DTzips$V1==21231]) # Answer = 127
rm(list = ls())
setwd('C://Users//ABaker//Documents//GitHub//Coursera//Getting and Cleaning Data')
library(httr)
library(httpuv)
library(jsonlite)
library(dplyr)
github <- oauth_endpoints("github")
myapp <- oauth_app("github", "9e975720d681777b66d4", "b2a99834bf1543521472d02fd031ed022c63e983")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1))
head(json2)
json2[json2$full_name == "jtleek/datasharing",] # 2013-11-07T13:25:07Z
rm(list = ls())
setwd('C:/Users/ABaker/Documents/GitHub/Coursera/Getting and Cleaning Data')
getwd()
list
list()
list.files()
X <- data.frame("var1"=sample(1:5), "var2"=sample(6:10), "Var3"=sample(11:15))
set.seed(13435)
X <- data.frame("var1"=sample(1:5), "var2"=sample(6:10), "Var3"=sample(11:15))
X
X <- X[sample(1:5),]
X
X$var2[c(1,3)] = NA
X
X[,1]
X[,"var1"]
X[1:2, "var2"]
X[(X$var1 <=3 & X$var3 > 11),]
X
X[(X$var1 <=3 & X$var3 > 11),]
X[(X$var1 <=3),]
X[(X$var1 <=3 && X$var3 > 11),]
X <- data.frame("var1"=sample(1:5), "var2"=sample(6:10), "var3"=sample(11:15))
X <- X[sample(1:5),]
X$var2[c(1,3)] = NA
X[(X$var1 <=3 & X$var3 > 11),]
X[(X$var1 <= 3 | X$var3 > 15),]
X[which(X$var2 > 8),]
X
set.seed(13435)
X <- data.frame("var1"=sample(1:5), "var2"=sample(6:10), "var3"=sample(11:15))
X <- X[sample(1:5),]
X$var2[c(1,3)] = NA
X
X[which(X$var2 > 8),]
X[(X$var2 > 8),]
X[which(X$var2 > 8),]
# compared to this
X[(X$var2 > 8),] # returns the NAs
sort(X$var1)
sort(X$var1,decreasing=TRUE)
sort(X$var2,na.last=TRUE)
X[order(X$var1),]
X[order(X$var1),]
X[order(X$var1,X$var3),]
libarary(plyr)
library(plyr)
arrange(X,var1)
arrange(X,desc(var1))
X$var4 <- rnorm(5)
X
Y <- cbind(X,rnorm(5))
Y
rm(list = ls())
setwd('C:/Users/ABaker/Documents/GitHub/Coursera/Getting and Cleaning Data')
list.files()
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
download.file(fileUrl,destfile="./data/restaurants.csv")
restData <- read.csv("./data/restaurants.csv")
restData
head(restData,n=3)
tail(restData,n=3)
summary(restData)
str(restData)
quantile(restData$councilDistrict,na.rm=TRUE)
quantile(restData$councilDistrict,probs=c(0.5,0.75,0.9))
table(restData$zipCode,useNA="ifany")
table(restData$councilDistrict,restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode > 0)
colSums(is.na(restData))
all(colSums(is.na(restData))==0)
table(restData$zipCode %in% c("21212"))
table(restData$zipCode %in% c("21212","21213"))
restData[restData$zipCode %in% c("21212","21213"),]
data(UCBAdmissions)
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit,data=DF)
xt
warpbreaks$replicate <- rep(1:9, len = 54)
xt <- xtabs(breaks ~.,data=warpbreaks)
xt
ftable(xt)
fakeData = rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData),units="Mb")
acs <- read.csv("./data/acs_wk3.csv")
rm(list = ls())
setwd('C://Users//ABaker//Documents//GitHub//Coursera//Getting and Cleaning Data')
setwd('C:/Users/ABaker/Documents/GitHub/Coursera/Getting and Cleaning Data')
acs <- read.csv("./data/acs_wk3.csv")
str(acs)
table(acs$ACR)
table(acs$AGS)
agricultureLogical <- acs$ACR == 3 & acs$AGS == 6
which(agricultureLogical) # First three values = 125, 238, 262
library(jpeg)
url2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
img <- readJPEG("./data/q2_wk3.jpg", native = TRUE)
head(img)
str(img)
quantile(img, c(0.3, 0.8))
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5,
col.names = c("Country.Code", "Rank", "V1", "Country.Name",
"GDP", "V2", "V3", "V4", "V5", "V6"))
head(gdp)
str(gdp)
summary(gdp)
gdp <- gdp[1:190,c(1,2,4,5)]
gdp
country <- read.csv("./data/wk3_Country.csv")
head(country)
mergedData = merge(gdp, country, by.x="Country.Code", by.y="CountryCode")
nrow(mergedData) # 189
head(mergedData[with(mergedData, order(Rank)), ])
rm(list = ls())
setwd('C:/Users/ABaker/Documents/GitHub/Coursera/Getting and Cleaning Data')
acs <- read.csv("./data/acs_wk3.csv")
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5,
col.names = c("Country.Code", "Rank", "V1", "Country.Name",
"GDP", "V2", "V3", "V4", "V5", "V6"))
head(gdp)
str(gdp)
summary(gdp)
gdp <- gdp[1:190,c(1,2,4,5)]
country <- read.csv("./data/wk3_Country.csv")
head(country)
mergedData = merge(gdp, country, by.x="Country.Code", by.y="CountryCode")
gdp
head(gdp)
as.numeric(gdp$Rank)
gdp[,]
head(gdp)
gdp[,gdp$Rank]
gdp[,Rank]
gdp[,gdp$Rank]
gdp$Rank
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5,
col.names = c("Country.Code", "Rank", "V1", "Country.Name",
"GDP", "V2", "V3", "V4", "V5", "V6"))
gdp <- gdp[1:190,c(1,2,4,5)]
gdp$Rank
gdp <- read.csv("./data/wk3_GDP.csv", header = FALSE, skip = 5,
col.names = c("Country.Code", "Rank", "V1", "Country.Name",
"GDP", "V2", "V3", "V4", "V5", "V6"))
gdp
head(gdp)
table(restData$Rank)
table(gdp$Rank)
head(gdp)
tail(gdp)
str(gdp)
restData <- read.csv("./data/restaurants.csv")
s1 <- seg(1,10,by=2); s1
s1 <- seq(1,10,by=2); s1
s2 <- seq(1,10,length=3); s2
x <- c(1,3,8,25,100); seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
restData$nearMe
table(restData$nearMe)
restData$zipWrong = ifelse(restData$zipCode < 0, TRUE, FALSE)
table(restData$zipWrong, restDAta$zipCode < 0)
table(restData$zipWrong, restData$zipCode < 0)
restData$zipGroups = cut(restData$zipCode, breaks=quantile(restData$zipCode))
table(restData$zipGroups)
table(restData$zipGroups, restData$zipCode)
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode,g=4)
table(restData$zipGroups)
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
class(restData$zcf)
yesno <- sample(c("yes", "no"), size=10, replace=TRUE)
yesno
yesnofac = factor(yesno, levels=c("yes", "no"))
yesnofac
relevel(yesnofac, ref="yes")
yesnofac
as.numeric(yesnofac)
library(plyr)
restData2 = mutate(restData,zipGroups=cut2(zipCode,g=4))
table(restData2$zipGroups)
gdp
